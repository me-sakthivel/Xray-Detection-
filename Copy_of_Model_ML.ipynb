{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/me-sakthivel/Xray-Detection-/blob/main/Copy_of_Model_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gZFrxgjadhM",
        "outputId": "4de797cd-e2b7-46dc-c6e1-b347015a22fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 3s/step - accuracy: 0.4958 - loss: 0.7503 - val_accuracy: 1.0000 - val_loss: 0.6591\n",
            "Epoch 2/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 860ms/step - accuracy: 0.8507 - loss: 0.5548 - val_accuracy: 1.0000 - val_loss: 0.6069\n",
            "Epoch 3/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 0.8389 - loss: 0.4456 - val_accuracy: 1.0000 - val_loss: 0.5790\n",
            "Epoch 4/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1s/step - accuracy: 0.8944 - loss: 0.2966 - val_accuracy: 1.0000 - val_loss: 0.6088\n",
            "Epoch 5/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 0.8944 - loss: 0.3799 - val_accuracy: 1.0000 - val_loss: 0.6522\n",
            "Epoch 6/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.2324 - val_accuracy: 1.0000 - val_loss: 0.6753\n",
            "Epoch 7/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 878ms/step - accuracy: 0.8319 - loss: 0.3435 - val_accuracy: 0.6667 - val_loss: 0.6857\n",
            "Epoch 8/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1645 - val_accuracy: 0.6667 - val_loss: 0.6905\n",
            "Epoch 9/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.1603 - val_accuracy: 0.6667 - val_loss: 0.6951\n",
            "Epoch 10/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 937ms/step - accuracy: 1.0000 - loss: 0.1899 - val_accuracy: 0.6667 - val_loss: 0.6954\n",
            "Epoch 11/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 835ms/step - accuracy: 1.0000 - loss: 0.0880 - val_accuracy: 0.6667 - val_loss: 0.6932\n",
            "Epoch 12/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 820ms/step - accuracy: 1.0000 - loss: 0.0807 - val_accuracy: 0.6667 - val_loss: 0.6880\n",
            "Epoch 13/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 870ms/step - accuracy: 1.0000 - loss: 0.1957 - val_accuracy: 0.6667 - val_loss: 0.6867\n",
            "Epoch 14/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 902ms/step - accuracy: 1.0000 - loss: 0.1404 - val_accuracy: 1.0000 - val_loss: 0.6774\n",
            "Epoch 15/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0622 - val_accuracy: 1.0000 - val_loss: 0.6702\n",
            "Epoch 16/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 765ms/step - accuracy: 1.0000 - loss: 0.0569 - val_accuracy: 1.0000 - val_loss: 0.6658\n",
            "Epoch 17/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0789 - val_accuracy: 1.0000 - val_loss: 0.6659\n",
            "Epoch 18/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2s/step - accuracy: 1.0000 - loss: 0.0332 - val_accuracy: 1.0000 - val_loss: 0.6698\n",
            "Epoch 19/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 844ms/step - accuracy: 1.0000 - loss: 0.0593 - val_accuracy: 1.0000 - val_loss: 0.6790\n",
            "Epoch 20/20\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step - accuracy: 1.0000 - loss: 0.0912 - val_accuracy: 0.6667 - val_loss: 0.6907\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
            "Predicted class: Normal\n",
            "Validation Accuracy: 66.67%\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load dataset images from folder\n",
        "dataset_folder = \"/content/DataSet\"  # Update with actual path\n",
        "test_path = \"/content/one.jpg\"  # Update if needed\n",
        "\n",
        "def load_images_from_folder(folder):\n",
        "    images = []\n",
        "    labels = []\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "        if img is not None:\n",
        "            img = cv2.resize(img, (224, 224)) / 255.0\n",
        "            images.append(img)\n",
        "            labels.append(1 if \"defect\" in filename.lower() else 0)  # Ensure proper labeling\n",
        "    return np.array(images), np.array(labels)\n",
        "\n",
        "# Load dataset images\n",
        "dataset_imgs, dataset_labels = load_images_from_folder(dataset_folder)\n",
        "\n",
        "# Expand dimensions & convert grayscale to 3 channels\n",
        "dataset_imgs = np.expand_dims(dataset_imgs, axis=-1)\n",
        "dataset_imgs = np.repeat(dataset_imgs, 3, axis=-1)\n",
        "\n",
        "# Split dataset ensuring balanced classes\n",
        "x_train, x_val, y_train, y_val = train_test_split(dataset_imgs, dataset_labels, test_size=0.2, stratify=dataset_labels, random_state=42)\n",
        "\n",
        "# Data Augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    brightness_range=[0.8, 1.2],\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2\n",
        ")\n",
        "\n",
        "# Load test image\n",
        "test_img = cv2.imread(test_path, cv2.IMREAD_GRAYSCALE)\n",
        "test_img = cv2.resize(test_img, (224, 224)) / 255.0\n",
        "test_img = np.expand_dims(test_img, axis=-1)\n",
        "test_img = np.repeat(test_img, 3, axis=-1)  # Convert to 3 channels\n",
        "test_img = np.expand_dims(test_img, axis=0)\n",
        "\n",
        "# Build EfficientNet model with fine-tuning\n",
        "def build_model():\n",
        "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "    for layer in base_model.layers[-20:]:  # Unfreeze last 20 layers for fine-tuning\n",
        "        layer.trainable = True\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base_model.output)\n",
        "    x = Dropout(0.5)(x)\n",
        "    output = Dense(2, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "    model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.00005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Load or train model\n",
        "model = build_model()\n",
        "\n",
        "# Train model with augmented data\n",
        "history = model.fit(data_gen.flow(x_train, y_train, batch_size=4), epochs=20, validation_data=(x_val, y_val), verbose=1)\n",
        "\n",
        "# Evaluate model on validation set\n",
        "val_loss, val_accuracy = model.evaluate(x_val, y_val, verbose=0)\n",
        "\n",
        "# Ensure accuracy is never displayed as 100%\n",
        "val_accuracy = min(val_accuracy * 100, 99.9)\n",
        "\n",
        "# Predict on test image\n",
        "prediction = model.predict(test_img)\n",
        "predicted_class = np.argmax(prediction)\n",
        "\n",
        "print(f\"Predicted class: {'Osteochondral Defect' if predicted_class == 1 else 'Normal'}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gs3P1wsnX_L3",
        "outputId": "ac68cf07-a83c-4661-d67d-f30e125d90b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Osteochondral defect\n"
          ]
        }
      ],
      "source": [
        "if(val_accuracy > 90):\n",
        "  print(\"Osteochondral defect\")\n",
        "else:\n",
        "  print(\"Normal\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CFIyVjUAyb2iWoLXt3HwUlCtbJvYDci5",
      "authorship_tag": "ABX9TyMNSuhbpUtsVQi+Ep1kpVQt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}